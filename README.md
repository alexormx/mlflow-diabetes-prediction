# ğŸ©º PredicciÃ³n de Diabetes con MLflow y Random Forest

Este proyecto implementa un flujo completo de Machine Learning tradicional para predecir la probabilidad de diabetes tipo 2 usando el dataset **Pima Indians Diabetes**. Se siguen buenas prÃ¡cticas de ingenierÃ­a de caracterÃ­sticas, comparaciÃ³n de modelos, selecciÃ³n basada en mÃ©tricas y registro con MLflow. AdemÃ¡s, se estructura como servicio de predicciÃ³n por lotes siguiendo la arquitectura propuesta por Pau Labarta.

---

## ğŸ¯ Objetivo del Proyecto

Predecir la presencia de diabetes a partir de variables clÃ­nicas usando modelos de clasificaciÃ³n tradicionales, optimizando el rendimiento mediante preprocesamiento, selecciÃ³n de caracterÃ­sticas, comparaciÃ³n de modelos y ajuste de hiperparÃ¡metros.

---

## ğŸ“¦ Dataset

El dataset contiene 768 registros con las siguientes variables:

- Glucose, BloodPressure, Insulin, BMI, Age, SkinThickness, etc.
- Variable target: `Outcome` (1 = Diabetes, 0 = No Diabetes)

---

## ğŸ“Š Flujo del Proyecto

El proyecto sigue el enfoque de **Batch-Prediction Service** propuesto por Pau Labarta:


- ğŸ“˜ Feature pipeline
- ğŸ“™ Training pipeline
- ğŸ“’ Batch inference pipeline

Cada etapa estÃ¡ contenida en un notebook independiente, garantizando modularidad, reproducibilidad y trazabilidad.

---

## ğŸ“ Estructura del proyecto

```bash
mlflow-diabetes-prediction/
â”‚
â”œâ”€â”€ data/                      # Dataset original y features procesados
â”‚   â”œâ”€â”€ diabetes.csv
â”‚   â””â”€â”€ features/
â”‚       â”œâ”€â”€ X_train.csv
â”‚       â”œâ”€â”€ X_test.csv
â”‚       â”œâ”€â”€ y_train.csv
â”‚       â””â”€â”€ y_test.csv
â”œâ”€â”€ models/                    # Modelos entrenados (pickle, etc.)
â”œâ”€â”€ notebooks/                 # Jupyter notebooks por etapa
â”‚   â”œâ”€â”€ 01_eda.ipynb
â”‚   â”œâ”€â”€ 02_preprocessing.ipynb
â”‚   â”œâ”€â”€ 03_training_validation.ipynb
â”‚   â””â”€â”€ 04_evaluation_export.ipynb
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## ğŸ“Š Dataset utilizado

- **Fuente**: [Kaggle - Pima Indians Diabetes Database](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database)
- **Registros**: 768 mujeres mayores de 21 aÃ±os
- **Variables**: 8 predictoras + 1 objetivo (`Outcome`: 1 = tiene diabetes, 0 = no)

---

## ğŸ” Pipeline del proyecto

### ğŸ“˜ 1. ExploraciÃ³n de Datos (EDA)
- VisualizaciÃ³n de distribuciones, outliers y valores faltantes
- AnÃ¡lisis de correlaciÃ³n entre variables
- IdentificaciÃ³n de datos fisiolÃ³gicamente imposibles

### ğŸ“˜ 2. Preprocesamiento
- ImputaciÃ³n conservadora de valores faltantes (mediana)
- Capping de outliers extremos por percentiles
- TransformaciÃ³n logarÃ­tmica de variables asimÃ©tricas
- AnÃ¡lisis de importancia de caracterÃ­sticas (`mutual_info_classif`)
- DivisiÃ³n en `train/test` y guardado de features para el pipeline de entrenamiento

### ğŸ“™ 3. Entrenamiento y ValidaciÃ³n
- ComparaciÃ³n de modelos con `LazyPredict`
- Entrenamiento de modelos con mejor desempeÃ±o (ej. Random Forest, Logistic Regression)
- JustificaciÃ³n de mÃ©tricas seleccionadas: se priorizÃ³ F1-score debido a la necesidad de balance entre Precision y Recall
- Registro de experimentos con **MLflow**

### ğŸ“’ 4. EvaluaciÃ³n final y exportaciÃ³n
- MÃ©tricas: Accuracy, Precision, Recall, F1, ROC AUC
- ExportaciÃ³n del modelo final y mÃ©tricas clave

---

## ğŸ” Hallazgos clave

- `Glucose`, `BMI`, `Age` y `Pregnancies` son las variables mÃ¡s informativas segÃºn `mutual_info_classif`.
- El anÃ¡lisis no evidenciÃ³ multicolinealidad significativa.
- Random Forest logrÃ³ el mejor rendimiento general (mayor F1).
- Se evitaron transformaciones innecesarias como escalado, ya que el modelo elegido no lo requerÃ­a.
- El preprocesamiento fue completamente modularizado y versionado.

---

## âš ï¸ Notas sobre escalado

El escalado (`StandardScaler`) **no se aplicÃ³** en esta etapa porque el modelo final seleccionado (Random Forest) **no lo requiere**.  
AdemÃ¡s, el anÃ¡lisis de importancia de caracterÃ­sticas con `mutual_info_classif` se realiza **antes del escalado**, ya que esta mÃ©trica **es invariante a transformaciones de escala**.

---

## ğŸ§ª Requisitos

```bash
pip install -r requirements.txt
```

---

## ğŸ” Reproducibilidad

```bash
git clone https://github.com/alexormx/mlflow-diabetes-prediction.git
cd mlflow-diabetes-prediction
python -m venv .venv
source .venv/bin/activate  # En Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

---

## âœï¸ Autor
Alejandro Ortiz Lopez  
[LinkedIn](https://www.linkedin.com/in/alexormx/) | GitHub: `@alexormx`

---

## ğŸ“Œ Licencia

Este proyecto se publica con fines educativos. Puedes usar y modificar el contenido respetando la fuente original del dataset (Kaggle).
