# ğŸ©º Diabetes Prediction with MLflow

Este proyecto aplica tÃ©cnicas de Machine Learning tradicional para predecir si una persona padece diabetes, utilizando el conocido dataset **Pima Indians Diabetes**. El enfoque incluye anÃ¡lisis exploratorio, preprocesamiento, modelado, evaluaciÃ³n y seguimiento de experimentos con MLflow.

---

## ğŸ“ Estructura del proyecto

```bash
mlflow-diabetes-prediction/
â”‚
â”œâ”€â”€ data/                      # Dataset original (CSV)
â”œâ”€â”€ models/                    # Modelos entrenados (opcional)
â”œâ”€â”€ notebooks/                 # Jupyter notebooks por etapa
â”‚   â”œâ”€â”€ 01_eda.ipynb           # AnÃ¡lisis exploratorio (EDA)
â”‚   â”œâ”€â”€ 02_preprocessing.ipynb # Limpieza, imputaciÃ³n, outliers
â”‚   â””â”€â”€ 03_model_training.ipynb# Entrenamiento y evaluaciÃ³n
â”‚
â”œâ”€â”€ mlruns/                    # Experimentos registrados por MLflow
â”œâ”€â”€ requirements.txt           # LibrerÃ­as necesarias
â”œâ”€â”€ README.md                  # Este archivo
â””â”€â”€ .gitignore                 # Archivos ignorados por git

---

## ğŸ“Š Dataset utilizado

- **Fuente**: [Kaggle - Pima Indians Diabetes Database](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database)
- **Registros**: 768 mujeres mayores de 21 aÃ±os
- **Variables**: 8 predictoras + 1 objetivo (`Outcome`: 1 = tiene diabetes, 0 = no)

---

## ğŸš€ Pipeline del proyecto

### 1. ExploraciÃ³n de Datos (EDA) â€“ `01_eda.ipynb`

- VisualizaciÃ³n y estadÃ­sticos generales del dataset.
- AnÃ¡lisis de la distribuciÃ³n por clase (`Outcome`).
- IdentificaciÃ³n de valores errÃ³neos como ceros fisiolÃ³gicamente imposibles.
- AnÃ¡lisis de correlaciÃ³n entre variables.

### 2. Preprocesamiento â€“ `02_preprocessing.ipynb`

- ImputaciÃ³n de valores faltantes (ceros invÃ¡lidos â†’ NaN).
- Tratamiento de outliers.
- Escalado de variables numÃ©ricas.
- SeparaciÃ³n en sets de entrenamiento y prueba.

### 3. Entrenamiento de modelos â€“ `03_model_training.ipynb`

- Modelos evaluados:
  - Logistic Regression
  - Random Forest
  - Support Vector Machine (SVM)
- MÃ©tricas comparadas: Accuracy, Precision, Recall, F1, ROC AUC
- Uso de MLflow para rastrear experimentos y parÃ¡metros

---

## ğŸ” Hallazgos clave

- `Glucose`, `BMI`, `Age` y `Pregnancies` son las variables mÃ¡s correlacionadas con la diabetes.
- No se detectÃ³ multicolinealidad severa entre variables predictoras.
- Se realizÃ³ imputaciÃ³n conservadora de valores faltantes (como ceros en presiÃ³n sanguÃ­nea, insulina, etc.).
- Random Forest obtuvo la mejor mÃ©trica F1 en los experimentos realizados.

---

## ğŸ§ª Requisitos

Instala las dependencias usando:

```bash
pip install -r requirements.txt

## ğŸ” Reproducibilidad

### 1. Clona el repositorio:

```bash
git clone https://github.com/alexormx/mlflow-diabetes-prediction.git
cd mlflow-diabetes-prediction

### 2. Crea y activa un entorno virtual:

```bash
python3 -m venv .venv
source .venv/bin/activate

---

### 3. Instala las dependencias:

```bash
pip install -r requirements.txt

---

### 4. Ejecuta los notebooks en orden desde Jupyter:
- 01_eda.ipynb
- 02_preprocessing.ipynb
- 03_model_training.ipynb

---

## âœï¸ Autor
Alejandro Ortiz Lopez
LinkedIn | GitHub

---

##  ğŸ“Œ Licencia
Este proyecto se publica con fines educativos. Puedes usar y modificar el contenido respetando la fuente original del dataset (Kaggle).

---