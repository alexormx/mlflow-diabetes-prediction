
# ğŸ” Diabetes Prediction with MLflow & Random Forest

Este proyecto utiliza **machine learning clÃ¡sico** (Random Forest Classifier) para predecir si un paciente presenta o no diabetes, con seguimiento de experimentos mediante **MLflow** y una arquitectura modular basada en la metodologÃ­a de **Pau Labarta**.

---

## ğŸ¯ Objetivo

Desarrollar un pipeline completo de clasificaciÃ³n binaria utilizando datos mÃ©dicos, enfocado en predecir la diabetes con un modelo clÃ¡sico optimizado y seguimiento de mÃ©tricas.

---

## ğŸ“¦ Dataset

- **Fuente:** Pima Indians Diabetes Database (Kaggle)
- **TamaÃ±o:** 768 muestras Ã— 9 columnas
- **Variables:** Glucosa, IMC, Edad, Embarazos, PresiÃ³n, Insulina, PedigrÃ­, etc.
- **Objetivo (Target):** 1 (diabÃ©tico), 0 (no diabÃ©tico)

---

## ğŸ§­ Estructura del Proyecto

```
mlflow-diabetes-prediction/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                  â† Dataset original
â”‚   â”œâ”€â”€ features/             â† X_train, y_train, X_test, y_test
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb
â”‚   â”œâ”€â”€ 02_preprocessing.ipynb
â”‚   â”œâ”€â”€ 03_training_validation.ipynb
â”‚   â”œâ”€â”€ 04_evaluation_export.ipynb
â”œâ”€â”€ models/                   â† Registro de modelos (MLflow)
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸ” Flujo del Proyecto (Pau Labarta)

1. **EDA & Preprocesamiento**  
   - RevisiÃ³n de nulos y valores atÃ­picos  
   - ImputaciÃ³n con mediana  
   - `Capping` de outliers severos  
   - `log-transform` para variables asimÃ©tricas  
   - `StandardScaler` aplicado  
   - SelecciÃ³n de caracterÃ­sticas vÃ­a `mutual_info_classif`

2. **Entrenamiento y ValidaciÃ³n**
   - EvaluaciÃ³n de +20 modelos con `LazyPredict`  
   - SelecciÃ³n de **Random Forest** por su balance entre desempeÃ±o y tiempo
   - AplicaciÃ³n de **SMOTE** para balanceo de clases
   - Ajuste de hiperparÃ¡metros (`max_depth`, `n_estimators`, `class_weight`, etc.)
   - Registro en **MLflow** con mÃ©tricas y artefactos

3. **EvaluaciÃ³n Final**
   - Matriz de confusiÃ³n, curva ROC, y mÃ©tricas de desempeÃ±o
   - ExportaciÃ³n del modelo

---

## ğŸ“Š MÃ©tricas Finales (Random Forest optimizado)

| MÃ©trica     | Valor     |
|-------------|-----------|
| Accuracy    | 0.7208    |
| Precision   | 0.6491    |
| Recall      | 0.6852    |
| F1-score    | 0.6504    |
| ROC AUC     | 0.7254    |

âœ… **SMOTE** ayudÃ³ a mejorar el recall para reducir falsos negativos (diagnÃ³sticos omitidos).

---

## ğŸ’¡ Recomendaciones Futuras

- ğŸ”„ Ajuste adicional con `Optuna` o `GridSearchCV` mÃ¡s extenso.
- âš–ï¸ Probar `class_weight='balanced_subsample'` o ensembles hÃ­bridos.
- ğŸ“ˆ ValidaciÃ³n cruzada con `StratifiedKFold`.
- ğŸ§ª Comparativa con modelos como `XGBoost`, `LightGBM`.
- ğŸš€ Publicar como API con FastAPI o desplegar vÃ­a Streamlit.

---

## ğŸ§ª EjecuciÃ³n

```
# Entrenar desde notebook principal
jupyter notebook notebooks/03_training_validation.ipynb
```

---

## ğŸ“ CrÃ©ditos

Desarrollado por [@alexormx](https://github.com/alexormx) como parte del portafolio final de **AiLab** â€“ Proyecto de clasificaciÃ³n binaria.