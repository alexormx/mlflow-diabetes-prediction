{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "404b597c",
   "metadata": {},
   "source": [
    "## üß† 03_training_validation.ipynb ‚Äì Entrenamiento y Validaci√≥n de Modelos\n",
    "\n",
    "Este notebook entrena y eval√∫a distintos modelos de clasificaci√≥n para predecir la presencia de diabetes en pacientes, utilizando el dataset ya preprocesado.  \n",
    "Se exploran modelos base, se comparan m√©tricas clave y se registra el experimento con MLflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72943e56",
   "metadata": {},
   "source": [
    "### 1. Carga del dataset limpio\n",
    "\n",
    "\n",
    "Cargamos el archivo `diabetes_clean.csv` generado durante el preprocesamiento.  \n",
    "Usamos `os.path.join` para construir rutas relativas seguras, ya que este notebook se encuentra en la carpeta `notebooks/` mientras que los datos est√°n en `data/`.\n",
    "\n",
    "> ‚ö†Ô∏è Si obtienes un error de archivo no encontrado (`FileNotFoundError`), aseg√∫rate de:\n",
    "> - Haber ejecutado completamente el notebook `02_preprocessing.ipynb`\n",
    "> - Estar en el directorio ra√≠z del proyecto al iniciar el entorno de notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ded001c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Insulin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1.764094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1.764094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1.764094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1.714496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1.813178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness   BMI  \\\n",
       "0            6    148.0           72.0           35.0  33.6   \n",
       "1            1     85.0           66.0           29.0  26.6   \n",
       "2            8    183.0           64.0           29.0  23.3   \n",
       "3            1     89.0           66.0           23.0  28.1   \n",
       "4            0    137.0           44.0           35.0  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome   Insulin  \n",
       "0                     0.627   50        1  1.764094  \n",
       "1                     0.351   31        0  1.764094  \n",
       "2                     0.672   32        1  1.764094  \n",
       "3                     0.167   21        0  1.714496  \n",
       "4                     2.288   33        1  1.813178  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Construcci√≥n de ruta robusta al archivo limpio\n",
    "file_path = os.path.join(\"..\", \"data\", \"diabetes_clean.csv\")\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9465eac5",
   "metadata": {},
   "source": [
    "### üîÑ 2. Separaci√≥n de variables independientes (X) y variable objetivo (y)\n",
    "\n",
    "En este paso separamos la variable objetivo `Outcome` del resto de los predictores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2343ffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar variables predictoras (X) y variable objetivo (y)\n",
    "X = df.drop(\"Outcome\", axis=1)\n",
    "y = df[\"Outcome\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5833f5",
   "metadata": {},
   "source": [
    "### üß™ 3. Divisi√≥n del dataset en entrenamiento y prueba\n",
    "\n",
    "Dividimos el dataset en un conjunto de entrenamiento (80%) y uno de prueba (20%), manteniendo la proporci√≥n de clases mediante `stratify=y`.  \n",
    "Esta divisi√≥n se hace **antes** de ajustar cualquier modelo para evitar data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a65dab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Divisi√≥n 80/20 con estratificaci√≥n\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae77593a",
   "metadata": {},
   "source": [
    "### üßæ 4. Verificaci√≥n de dimensiones\n",
    "\n",
    "Revisamos las dimensiones de los conjuntos para confirmar que la divisi√≥n fue exitosa y las proporciones se mantuvieron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57f56cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de X_train: (614, 8)\n",
      "Shape de X_test: (154, 8)\n",
      "Shape de y_train: (614,)\n",
      "Shape de y_test: (154,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape de X_train:\", X_train.shape)\n",
    "print(\"Shape de X_test:\", X_test.shape)\n",
    "print(\"Shape de y_train:\", y_train.shape)\n",
    "print(\"Shape de y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8f22f9",
   "metadata": {},
   "source": [
    "### 5. üîÑ Escalado de caracter√≠sticas\n",
    "\n",
    "Aplicamos `StandardScaler` para escalar las variables predictoras. Esta t√©cnica transforma los datos para que tengan media 0 y desviaci√≥n est√°ndar 1. Es importante ajustar el escalador √∫nicamente con el conjunto de entrenamiento para evitar data leakage.\n",
    "\n",
    "Transformamos `X_train` y `X_test` usando este escalador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20395a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media (X_train_scaled): [-6.94341436e-17 -1.09937394e-16 -1.66352636e-16 -6.94341436e-17\n",
      "  6.27800381e-16 -1.09937394e-16 -1.08490849e-16 -5.11353536e-16]\n",
      "Desviaci√≥n est√°ndar (X_train_scaled): [1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Inicializar el escalador\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajustar solo con datos de entrenamiento\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transformar tambi√©n el conjunto de prueba\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Media (X_train_scaled):\", np.mean(X_train_scaled, axis=0))\n",
    "print(\"Desviaci√≥n est√°ndar (X_train_scaled):\", np.std(X_train_scaled, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f5cd23",
   "metadata": {},
   "source": [
    "\n",
    "#### üíæ Guardado de datos procesados\n",
    "\n",
    "Se almacenan los conjuntos de datos `X_train_scaled`, `X_test_scaled`, `y_train`, `y_test` como archivos `.pkl` para reutilizarlos en el notebook `04_evaluation_export.ipynb` sin tener que repetir el preprocesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32d17e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Datos escalados guardados exitosamente en ../data/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "# Crear carpeta ../data si no existe\n",
    "os.makedirs('../data', exist_ok=True)\n",
    "\n",
    "# Guardar datasets escalados desde notebooks/\n",
    "joblib.dump(X_train_scaled, '../data/X_train_scaled.pkl')\n",
    "joblib.dump(X_test_scaled, '../data/X_test_scaled.pkl')\n",
    "joblib.dump(y_train, '../data/y_train.pkl')\n",
    "joblib.dump(y_test, '../data/y_test.pkl')\n",
    "\n",
    "print(\"‚úÖ Datos escalados guardados exitosamente en ../data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e68ba48",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### ‚úÖ Conclusiones de la etapa de validaci√≥n y escalado\n",
    "\n",
    "- Se realiz√≥ una correcta divisi√≥n del dataset en entrenamiento y prueba con una proporci√≥n 80/20, utilizando estratificaci√≥n para conservar la proporci√≥n de clases en ambos subconjuntos.\n",
    "- Se aplic√≥ `StandardScaler` exclusivamente con los datos de entrenamiento y luego se transformaron los datos de prueba, siguiendo buenas pr√°cticas para evitar filtraci√≥n de datos.\n",
    "- Se verific√≥ que los datos escalados tienen media cercana a 0 y desviaci√≥n est√°ndar igual a 1.\n",
    "- Finalmente, se guardaron los conjuntos escalados en archivos `.pkl` utilizando `joblib` para su reutilizaci√≥n posterior en el m√≥dulo `04_evaluation_export.ipynb`.\n",
    "\n",
    "Este enfoque modular facilita el entrenamiento y la evaluaci√≥n de modelos de manera eficiente, reproducible y alineada con buenas pr√°cticas de ciencia de datos.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv - Diabetes)",
   "language": "python",
   "name": "diabetes_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
